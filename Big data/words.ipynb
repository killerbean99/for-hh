{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as pst\n",
    "import PIL.Image as pi\n",
    "import cv2\n",
    "from pytesseract import Output\n",
    "from wand.image import Image as wii\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import string\n",
    "import IPython.display as Ipd\n",
    "from glob import glob as gg\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preporition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning text from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text recognition configuration\n",
    "MY_CONFIG = r\"--psm 3 --oem 3 -l eng\" # --psm 3, 6\n",
    "\n",
    "# Images link\n",
    "PNG_FILES = gg('./png/*.png')\n",
    "\n",
    "# Files that we use for\n",
    "test_files_ix = [2, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_ix(filename):\n",
    "    filename = filename[filename.index('\\\\'):]\n",
    "    \n",
    "    for char in filename:\n",
    "        if char.isnumeric():\n",
    "            first_digit_ix = filename.index(char)\n",
    "            filename = filename[first_digit_ix:]\n",
    "\n",
    "            for char in filename:\n",
    "                if not char.isnumeric():\n",
    "                    last_digit_ix = filename.index(char)\n",
    "                    filename = filename[:last_digit_ix]\n",
    "                    \n",
    "                    return int(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_ix(filename):\n",
    "    filename = filename[::-1]\n",
    "\n",
    "    for char in filename:\n",
    "        if char.isnumeric():\n",
    "            first_digit_ix = filename.index(char)\n",
    "            filename = filename[first_digit_ix:]\n",
    "\n",
    "            for char in filename:\n",
    "                if not char.isnumeric():\n",
    "                    last_digit_ix = filename.index(char)\n",
    "                    filename = filename[:last_digit_ix]\n",
    "                    filename = filename[::-1]\n",
    "                    \n",
    "                    return int(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list_doc1 = []\n",
    "text_list_doc2 = []\n",
    "text_list_doc3 = []\n",
    "\n",
    "header_list = []\n",
    "footer_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header(list1, list2, have_a_header):\n",
    "    new_list = []\n",
    "    \n",
    "    for word in list1:\n",
    "        if word in list2:\n",
    "            new_list.append(word)\n",
    "            have_a_header = True\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_footer(list1, list2, have_a_footer):\n",
    "    new_list = []\n",
    "\n",
    "    # for word in list1:\n",
    "    #     if not word.isalpha():\n",
    "    #         list1.remove(word)\n",
    "    \n",
    "    # for word in list2:\n",
    "    #     if not word.isalpha():\n",
    "    #         list1.remove(word)\n",
    "\n",
    "    list1.reverse()\n",
    "    list2.reverse()\n",
    "\n",
    "    for word in list1:\n",
    "        if word in list2:\n",
    "            new_list.append(word)\n",
    "            have_a_footer = True\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text1 = []\n",
    "train_text2 = []\n",
    "train_text3 = []\n",
    "train_text4 = []\n",
    "train_text5 = []\n",
    "train_text6 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_page = []\n",
    "have_a_header = False\n",
    "have_a_footer = False\n",
    "\n",
    "for file in PNG_FILES:\n",
    "    test_text = pst.image_to_string(pi.open(file), config = MY_CONFIG)\n",
    "    page = test_text.split()\n",
    "    \n",
    "    if (doc_ix(file) in test_files_ix):\n",
    "        if doc_ix(file) == test_files_ix[0] and img_ix(file) >= 4:\n",
    "            text_list_doc1 += page\n",
    "        elif doc_ix(file) == test_files_ix[1] and img_ix(file) >= 20:\n",
    "            text_list_doc2 += page\n",
    "        elif doc_ix(file) == test_files_ix[2] and (img_ix(file) >= 6 and img_ix(file) <= 14):\n",
    "            text_list_doc3 += page\n",
    "        \n",
    "        if prev_page and not have_a_header:\n",
    "            header_list += get_header(prev_page, page, have_a_header)\n",
    "        \n",
    "        if prev_page and not have_a_footer:\n",
    "            footer_list += get_footer(prev_page, page, have_a_footer)\n",
    "        \n",
    "        prev_page = page\n",
    "        \n",
    "    else:\n",
    "        if doc_ix(file) == 1 and img_ix(file) <= 18:\n",
    "            train_text1 += page\n",
    "        elif doc_ix(file) == 3:\n",
    "            train_text2 += page\n",
    "        elif doc_ix(file) == 4 and (img_ix(file) == 6 or img_ix(file) == 7 or (img_ix(file) >= 12 and img_ix(file) <= 14) or img_ix(file) >= 23):\n",
    "            train_text3 += page\n",
    "        elif doc_ix(file) == 5 and img_ix(file) >= 6:\n",
    "            train_text4 += page\n",
    "        elif doc_ix(file) == 6:\n",
    "            train_text5 += page\n",
    "        elif doc_ix(file) == 8 and img_ix(file) >= 9:\n",
    "            train_text6 += page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list_doc = text_list_doc1 + text_list_doc2 + text_list_doc3\n",
    "\n",
    "text_list_doc = [item for item in text_list_doc if item not in header_list]\n",
    "text_list_doc = [item for item in text_list_doc if item not in footer_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7559"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_text_elements = len(text_list_doc)\n",
    "origin_text_elements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuctions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Punctuation and Save words in Uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_id(val, idx):\n",
    "    return (idx, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['the', 'of', 'and', 'in', 'to', 'for', 'is',\n",
    "              'as', 'with', 'on', 'are', 'this', 'that', 'it', \n",
    "              'by', 'an', 'be', 'was', 'has', 'such', 'from',\n",
    "              'he', 'all', 'use', 'new', 'its', 'which', 'their',\n",
    "              'can', 'at', 'where', 'when', 'not', 'if', 'there',\n",
    "              'or', 'you', 'they', 'each', 'have', 'them', 'these',\n",
    "              'out', 'then', 'etc', 'time', 'also', 'we', 'thus',\n",
    "              'about', 'should', 'lets', 'will']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(any_list):\n",
    "    lower_list = []\n",
    "    lower_id = []\n",
    "    \n",
    "    upper_list = []\n",
    "    upper_id = []\n",
    "\n",
    "    name_list = []\n",
    "    name_id = []\n",
    "\n",
    "    id = 0\n",
    "    \n",
    "    for word in any_list:\n",
    "        word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        if len(word) > 1 and word.lower() not in stop_words:\n",
    "            if word.isupper():\n",
    "                upper_list.append(word)\n",
    "                upper_id.append(id)\n",
    "\n",
    "            elif word.islower():\n",
    "                lower_list.append(word)\n",
    "                lower_id.append(id)\n",
    "            \n",
    "            elif word.isalpha():\n",
    "                name_list.append(word)\n",
    "                name_id.append(id)\n",
    "            \n",
    "            id += 1\n",
    "\n",
    "    for word in name_list:\n",
    "        if word.lower() in name_list:\n",
    "            name_list.remove(word)\n",
    "    \n",
    "    for word in upper_list:\n",
    "        if word.lower() in upper_list:\n",
    "            upper_list.remove(word)\n",
    "\n",
    "    upper_map = list(map(add_id, upper_list, upper_id))\n",
    "    lower_map = list(map(add_id, lower_list, lower_id))\n",
    "    name_map = list(map(add_id, name_list, name_id))\n",
    "\n",
    "    return upper_map, name_map, lower_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppers, names, lowers = func(text_list_doc)\n",
    "all_words = uppers + names + lowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppers1, names1, lowers1 = func(train_text1)\n",
    "uppers2, names2, lowers2 = func(train_text2)\n",
    "uppers3, names3, lowers3 = func(train_text3)\n",
    "uppers4, names4, lowers4 = func(train_text4)\n",
    "uppers5, names5, lowers5 = func(train_text5)\n",
    "uppers6, names6, lowers6 = func(train_text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text1_map = uppers1 + names1 + lowers1\n",
    "train_text2_map = uppers2 + names2 + lowers2\n",
    "train_text3_map = uppers3 + names3 + lowers3\n",
    "train_text4_map = uppers4 + names4 + lowers4\n",
    "train_text5_map = uppers5 + names5 + lowers5\n",
    "train_text6_map = uppers6 + names6 + lowers6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(map_list, filename):\n",
    "    df = pd.DataFrame(map_list, columns=['id', 'word'])\n",
    "    df = df.sort_values('id').set_index('id')\n",
    "    df['second word'] = df['word'].shift(-1)\n",
    "    df['2 words'] = df['word'] + ' ' + df['second word']\n",
    "    df = df.drop(columns=['word', 'second word'])\n",
    "    dps = df.duplicated()\n",
    "    duplicate_rows = df[dps]\n",
    "    duplicate_rows = duplicate_rows.drop_duplicates()\n",
    "    duplicate_rows.to_csv(filename)\n",
    "    return duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv2(map_list, filename):\n",
    "    df = pd.DataFrame(map_list, columns=['id', 'word'])\n",
    "    df = df.sort_values('id').set_index('id')\n",
    "    df['second word'] = df['word'].shift(-1)\n",
    "    df['2 words'] = df['word'] + ' ' + df['second word']\n",
    "    df = df.drop(columns=['word', 'second word'])\n",
    "    df.to_csv(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_df = to_csv2(train_text1_map, './db/train_text1')\n",
    "train2_df = to_csv2(train_text2_map, './db/train_text2')\n",
    "train3_df = to_csv2(train_text3_map, './db/train_text3')\n",
    "train4_df = to_csv2(train_text4_map, './db/train_text4')\n",
    "train5_df = to_csv2(train_text5_map, './db/train_text5')\n",
    "train6_df = to_csv2(train_text6_map, './db/train_text6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(any_list):\n",
    "    splited_list = []\n",
    "\n",
    "    for line in any_list:\n",
    "        line = line.split()\n",
    "        for word in line:\n",
    "            splited_list.append(word)\n",
    "    \n",
    "    return splited_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_engine = ['game engine',\n",
    "               'mobile games',\n",
    "               'Unity 3D',\n",
    "               'game engines',\n",
    "               'engine Unity',\n",
    "               'mobile games',\n",
    "               'Unity UDK',\n",
    "               'levels design',\n",
    "               'Torque 2D3D']\n",
    "\n",
    "environment = ['climatic ecological', \n",
    "               'state environment', \n",
    "               'observations state', \n",
    "               'air pollution', \n",
    "               'state atmospheric air', \n",
    "               'observations carried', \n",
    "               'air carried', \n",
    "               'RSE Kazhydromet', \n",
    "               'air quality', \n",
    "               'dust meter', \n",
    "               'pollution control', \n",
    "               'Atmospheric pollution', \n",
    "               'emissions pollutants', \n",
    "               'current state']\n",
    "\n",
    "physics = ['physical processes',\n",
    "           'physical laboratory',\n",
    "           'physics sections',\n",
    "           'real environment',\n",
    "           'physical experiments',\n",
    "           'physical laboratories',\n",
    "           'general physics',\n",
    "           'Diffraction electrons',\n",
    "           'Physical experiment',\n",
    "           'speed bullet',\n",
    "           'Determination coefficient',\n",
    "           'Measurement speed',\n",
    "           'Verification Malus',\n",
    "           'polarized light',\n",
    "           '3D models']\n",
    "\n",
    "robotics = ['using controller',\n",
    "            'sensitivity receiver',\n",
    "            'LoRa technology']\n",
    "\n",
    "it_list = ['levels design',\n",
    "           'create software',\n",
    "           'user interface',\n",
    "           'programming language',\n",
    "           'software complex',\n",
    "           'startype network',\n",
    "           'mobile communication',\n",
    "           'local station',\n",
    "           'base station',\n",
    "           'through web',\n",
    "           'network fragment',\n",
    "           'based ARM',\n",
    "           'parameters electronic',\n",
    "           'electronic processing',\n",
    "           'processing devices',\n",
    "           'MIT Media',\n",
    "           'LPWAN technology',\n",
    "           'IoT applications',\n",
    "           'LPWAN technologies',\n",
    "           'wireless technologies']\n",
    "\n",
    "education = ['teaching physics',   \n",
    "             'laboratory works',    \n",
    "             'academic programs',    \n",
    "             'physics course',    \n",
    "             'technical academic',    \n",
    "             'laboratory work',    \n",
    "             'educational software',    \n",
    "             'virtual laboratories',  \n",
    "             'Associate professor',\n",
    "             'Mathematical modelling',\n",
    "             'Phd candidate',\n",
    "             'Data analysis',\n",
    "             'Mathematics School',\n",
    "             'good example',\n",
    "             'computer-based learning',    \n",
    "             'learning systems',    \n",
    "             'secondary schools',    \n",
    "             'educational institutions',\n",
    "             'learning tools',\n",
    "             'learning process',\n",
    "             'point view',\n",
    "             'educational process',\n",
    "             'medical education',\n",
    "             'high level knowledge',\n",
    "             'teaching methods',\n",
    "             'educational games']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_engine = split_list(game_engine)\n",
    "environment = split_list(environment)\n",
    "physics = split_list(physics)\n",
    "robotics = split_list(robotics)\n",
    "it_list = split_list(it_list)\n",
    "education = split_list(education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['teaching',\n",
       " 'physics',\n",
       " 'laboratory',\n",
       " 'works',\n",
       " 'academic',\n",
       " 'programs',\n",
       " 'physics',\n",
       " 'course',\n",
       " 'technical',\n",
       " 'academic',\n",
       " 'laboratory',\n",
       " 'work',\n",
       " 'educational',\n",
       " 'software',\n",
       " 'virtual',\n",
       " 'laboratories',\n",
       " 'Associate',\n",
       " 'professor',\n",
       " 'Mathematical',\n",
       " 'modelling',\n",
       " 'Phd',\n",
       " 'candidate',\n",
       " 'Data',\n",
       " 'analysis',\n",
       " 'Mathematics',\n",
       " 'School',\n",
       " 'good',\n",
       " 'example',\n",
       " 'computer-based',\n",
       " 'learning',\n",
       " 'learning',\n",
       " 'systems',\n",
       " 'secondary',\n",
       " 'schools',\n",
       " 'educational',\n",
       " 'institutions',\n",
       " 'learning',\n",
       " 'tools',\n",
       " 'learning',\n",
       " 'process',\n",
       " 'point',\n",
       " 'view',\n",
       " 'educational',\n",
       " 'process',\n",
       " 'medical',\n",
       " 'education',\n",
       " 'high',\n",
       " 'level',\n",
       " 'knowledge',\n",
       " 'teaching',\n",
       " 'methods',\n",
       " 'educational',\n",
       " 'games']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = to_csv(all_words, './db/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_in_ge = all_df['2 words'].isin(game_engine)\n",
    "is_in_env = all_df['2 words'].isin(environment)\n",
    "is_in_ph = all_df['2 words'].isin(physics)\n",
    "is_in_rb = all_df['2 words'].isin(robotics)\n",
    "is_in_it = all_df['2 words'].isin(it_list)\n",
    "is_in_edu = all_df['2 words'].isin(education)\n",
    "\n",
    "if (is_in_ge == True).any():\n",
    "    all_df.loc[is_in_ge, 'type'] = 'game engine'\n",
    "if (is_in_env == True).any():\n",
    "    all_df.loc[is_in_env, 'type'] = 'environment'\n",
    "if (is_in_ph == True).any():\n",
    "    all_df.loc[is_in_ph, 'type'] = 'physics'\n",
    "if (is_in_rb == True).any():\n",
    "    all_df.loc[is_in_rb, 'type'] = 'robotics'\n",
    "if (is_in_it == True).any():\n",
    "    all_df.loc[is_in_it, 'type'] = 'IT'\n",
    "if (is_in_edu == True).any():\n",
    "    all_df.loc[is_in_edu, 'type'] = 'education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_df(train_df):\n",
    "    train_df.loc[train_df['2 words'].isin(all_df['2 words']), 'type'] = all_df['type'].fillna('unknown')\n",
    "    type_counts = train_df['type'].value_counts()\n",
    "    pie_chart = type_counts.plot.pie(figsize=(5, 5))\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Elara\\OneDrive\\Документы\\Big data\\words.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_df \u001b[39m=\u001b[39m all_df\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m circle_df(all_df)\n",
      "\u001b[1;32mc:\\Users\\Elara\\OneDrive\\Документы\\Big data\\words.ipynb Cell 33\u001b[0m in \u001b[0;36mcircle_df\u001b[1;34m(train_df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcircle_df\u001b[39m(train_df):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_df\u001b[39m.\u001b[39mloc[train_df[\u001b[39m'\u001b[39m\u001b[39m2 words\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(all_df[\u001b[39m'\u001b[39m\u001b[39m2 words\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_df[\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     type_counts \u001b[39m=\u001b[39m train_df[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pie_chart \u001b[39m=\u001b[39m type_counts\u001b[39m.\u001b[39mplot\u001b[39m.\u001b[39mpie(figsize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'type'"
     ]
    }
   ],
   "source": [
    "all_df = all_df.dropna()\n",
    "circle_df(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Elara\\OneDrive\\Документы\\Big data\\words.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train1_df \u001b[39m=\u001b[39m train1_df\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m circle_df(train1_df)\n",
      "\u001b[1;32mc:\\Users\\Elara\\OneDrive\\Документы\\Big data\\words.ipynb Cell 34\u001b[0m in \u001b[0;36mcircle_df\u001b[1;34m(train_df)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcircle_df\u001b[39m(train_df):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_df\u001b[39m.\u001b[39mloc[train_df[\u001b[39m'\u001b[39m\u001b[39m2 words\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(all_df[\u001b[39m'\u001b[39m\u001b[39m2 words\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_df[\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     type_counts \u001b[39m=\u001b[39m train_df[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Elara/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Big%20data/words.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pie_chart \u001b[39m=\u001b[39m type_counts\u001b[39m.\u001b[39mplot\u001b[39m.\u001b[39mpie(figsize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Elara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'type'"
     ]
    }
   ],
   "source": [
    "train1_df = train1_df.dropna()\n",
    "circle_df(train1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_words = all_df.loc[all_df['type'] == 'game engine', '2 words']\n",
    "env_words = all_df.loc[all_df['type'] == 'environment', '2 words']\n",
    "ph_words = all_df.loc[all_df['type'] == 'physics', '2 words']\n",
    "rb_words = all_df.loc[all_df['type'] == 'robotics', '2 words']\n",
    "it_words = all_df.loc[all_df['type'] == 'IT', '2 words']\n",
    "edu_words = all_df.loc[all_df['type'] == 'education', '2 words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(train_df):\n",
    "    any_list = train_df.tolist()\n",
    "    return any_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list2(train_df):\n",
    "    any_list = train_df['2 words'].tolist()\n",
    "    return any_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_list = get_list(ge_words)\n",
    "class2_list = get_list(env_words)\n",
    "class3_list = get_list(ph_words)\n",
    "class4_list = get_list(rb_words)\n",
    "class5_list = get_list(it_words)\n",
    "class6_list = get_list(edu_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['game engine',\n",
       " 'Unity 3D',\n",
       " 'game engines',\n",
       " 'engine Unity',\n",
       " 'mobile games',\n",
       " 'Unity UDK',\n",
       " 'Torque 2D3D']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_words = get_list2(train1_df)\n",
    "train2_words = get_list2(train2_df)\n",
    "train3_words = get_list2(train3_df)\n",
    "train4_words = get_list2(train4_df)\n",
    "train5_words = get_list2(train5_df)\n",
    "train6_words = get_list2(train6_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(train_words):\n",
    "    class1_count = 0\n",
    "    class2_count = 0\n",
    "    class3_count = 0\n",
    "    class4_count = 0\n",
    "    class5_count = 0\n",
    "    class6_count = 0\n",
    "\n",
    "    for word in train_words:\n",
    "        if word in class1_list:\n",
    "            class1_count += 1\n",
    "        elif word in class2_list:\n",
    "            class2_count += 1\n",
    "        elif word in class3_list:\n",
    "            class3_count += 1\n",
    "        elif word in class4_list:\n",
    "            class4_count += 1\n",
    "        elif word in class5_list:\n",
    "            class5_count += 1\n",
    "        elif word in class6_list:\n",
    "            class6_count += 1\n",
    "    \n",
    "    class1_count = class1_count / len(class1_list)\n",
    "    class2_count = class2_count / len(class2_list)\n",
    "    class3_count = class3_count / len(class3_list)\n",
    "    class4_count = class4_count / len(class4_list)\n",
    "    class5_count = class5_count / len(class5_list)\n",
    "    class6_count = class6_count / len(class6_list)\n",
    "\n",
    "    print(class1_count, class2_count, class3_count, class4_count, class5_count, class6_count)\n",
    "    \n",
    "    max_class = max(class1_count, class2_count, class3_count, class4_count, class5_count, class6_count)\n",
    "\n",
    "    if class1_count == max_class:\n",
    "        return 'Game Engine'\n",
    "    elif class2_count == max_class:\n",
    "        return 'Environment'\n",
    "    elif class3_count == max_class:\n",
    "        return 'Physics'\n",
    "    elif class4_count == max_class:\n",
    "        return 'Robotics'\n",
    "    elif class5_count == max_class:\n",
    "        return 'IT'\n",
    "    elif class6_count == max_class:\n",
    "        return 'Education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5714285714285716 0.0 0.0 0.0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Game Engine'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(train1_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 0.0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Game Engine'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(train2_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 0.0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Game Engine'"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(train3_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 0.0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Game Engine'"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(train4_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 0.0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Game Engine'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(train5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 0.0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Game Engine'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(train6_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcaaa2e39c35ecc5001cadf1314525f3ff006f3ae901308fe8b734a4c41a783a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
